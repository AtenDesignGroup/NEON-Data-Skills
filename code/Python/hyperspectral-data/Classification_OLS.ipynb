{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as mplt\n",
    "from scipy import linalg\n",
    "from scipy import io\n",
    "\n",
    "### Ordinary Least Squares\n",
    "### SOLVES 2-CLASS LEAST SQUARES PROBLEM\n",
    "\n",
    "### LOAD DATA ###\n",
    "### IF LoadClasses IS True, THEN LOAD DATA FROM FILES ###\n",
    "### OTHERSIE, RANDOMLY GENERATE DATA ###\n",
    "LoadClasses    = False\n",
    "TrainOutliers  = False\n",
    "TestOutliers   = False\n",
    "NOut           = 20\n",
    "NSampsClass    = 200\n",
    "NSamps         = 2*NSampsClass\n",
    "\n",
    "if LoadClasses:\n",
    "    \n",
    "    ### GET FILENAMES %%%\n",
    "    ### THESE ARE THE OPTIONS ###\n",
    "    ### LinSepC1, LinSepC2,LinSepC2Outlier (Still Linearly Separable) ###\n",
    "    ### NonLinSepC1, NonLinSepC2, NonLinSepC22 ###\n",
    "    \n",
    "    InFile1          = 'NonLinSepC1.mat'\n",
    "    InFile2          = 'NonLinSepC22.mat'\n",
    "    C1Dict           = io.loadmat(InFile1)\n",
    "    C2Dict           = io.loadmat(InFile2)\n",
    "    C1               = C1Dict['NonLinSepC1']\n",
    "    C2               = C2Dict['NonLinSepC22']\n",
    "    \n",
    "    if TrainOutliers:\n",
    "        ### Let's Make Some Noise ###\n",
    "        Out1        = 2*np.random.rand(NOut,2)-0.5\n",
    "        Out2        = 2*np.random.rand(NOut,2)-0.5\n",
    "        C1          = np.concatenate((C1,Out1),axis=0)\n",
    "        C2          = np.concatenate((C2,Out2),axis=0)\n",
    "        NSampsClass = NSampsClass+NOut\n",
    "        NSamps      = 2*NSampsClass\n",
    "else:\n",
    "    ### Randomly Generate Some Data\n",
    "    ### Make a covariance using a diagonal array and rotation matrix\n",
    "    pi      = 3.141592653589793\n",
    "    Lambda1 = 0.25\n",
    "    Lambda2 = 0.05\n",
    "    DiagMat = np.array([[Lambda1, 0.0],[0.0, Lambda2]])\n",
    "    RotMat  = np.array([[np.sin(pi/4), np.cos(pi/4)], [-np.cos(pi/4), np.sin(pi/4)]])\n",
    "    mu1     = np.array([0,0])\n",
    "    mu2     = np.array([1,1])\n",
    "    Sigma   = np.dot(np.dot(RotMat.T, DiagMat), RotMat)\n",
    "    C1      = np.random.multivariate_normal(mu1, Sigma, NSampsClass)\n",
    "    C2      = np.random.multivariate_normal(mu2, Sigma, NSampsClass)\n",
    "    print(Sigma)\n",
    "    print(C1.shape)\n",
    "    print(C2.shape)\n",
    "\n",
    "### PLOT DATA ###\n",
    "matplotlib.pyplot.figure(1)\n",
    "matplotlib.pyplot.plot(C1[:NSampsClass, 0], C1[:NSampsClass, 1], 'bo')\n",
    "matplotlib.pyplot.plot(C2[:NSampsClass, 0], C2[:NSampsClass, 1], 'ro')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### SET UP TARGET OUTPUTS ###\n",
    "TargetOutputs          = np.ones((NSamps,1))\n",
    "TargetOutputs[NSampsClass:NSamps] = -TargetOutputs[NSampsClass:NSamps]\n",
    "\n",
    "### PLOT TARGET OUTPUTS ###\n",
    "matplotlib.pyplot.figure(2)\n",
    "matplotlib.pyplot.plot(range(NSampsClass),         TargetOutputs[range(NSampsClass)],   'b-')\n",
    "matplotlib.pyplot.plot(range(NSampsClass, NSamps), TargetOutputs[range(NSampsClass, NSamps)], 'r-')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### FIND LEAST SQUARES SOLUTION ###\n",
    "AllSamps     = np.concatenate((C1,C2),axis=0)\n",
    "AllSampsBias = np.concatenate((AllSamps, np.ones((NSamps,1))), axis=1)\n",
    "Pseudo       = linalg.pinv2(AllSampsBias)\n",
    "w            = Pseudo.dot(TargetOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### COMPUTE OUTPUTS ON TRAINING DATA ###\n",
    "y = AllSampsBias.dot(w)\n",
    "\n",
    "### PLOT OUTPUTS FROM TRAINING DATA ###\n",
    "matplotlib.pyplot.figure(3)\n",
    "matplotlib.pyplot.plot(range(NSamps), y, 'm')\n",
    "matplotlib.pyplot.plot(range(NSamps),np.zeros((NSamps,1)), 'b')\n",
    "matplotlib.pyplot.plot(range(NSamps), TargetOutputs, 'k')\n",
    "matplotlib.pyplot.title('TrainingOutputs (Magenta) vs Desired Outputs (Black)')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### CALCULATE AND PLOT LINEAR DISCRIMINANT ###\n",
    "Slope     = -w[1]/w[0]\n",
    "Intercept = -w[2]/w[0]\n",
    "Domain    = np.linspace(-1.1, 1.1, 60)\n",
    "Disc      = Slope*Domain+Intercept\n",
    "\n",
    "matplotlib.pyplot.figure(4)\n",
    "matplotlib.pyplot.plot(C1[:NSampsClass, 0], C1[:NSampsClass, 1], 'bo')\n",
    "matplotlib.pyplot.plot(C2[:NSampsClass, 0], C2[:NSampsClass, 1], 'ro')\n",
    "matplotlib.pyplot.plot(Domain, Disc, 'k-')\n",
    "matplotlib.pyplot.ylim([-1.1,1.3])\n",
    "matplotlib.pyplot.title('Ordinary Least Squares')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RegConst      = 0.1\n",
    "AllSampsBias  = np.concatenate((AllSamps, np.ones((NSamps,1))), axis=1)\n",
    "AllSampsBiasT = AllSampsBias.T\n",
    "XtX           = AllSampsBiasT.dot(AllSampsBias)\n",
    "AllSampsReg   = XtX + RegConst*np.eye(3)\n",
    "Pseudo        = linalg.pinv2(AllSampsReg)\n",
    "wr            = Pseudo.dot(AllSampsBiasT.dot(TargetOutputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Slope     = -wr[1]/wr[0]\n",
    "Intercept = -wr[2]/wr[0]\n",
    "Domain    = np.linspace(-1.1, 1.1, 60)\n",
    "Disc      = Slope*Domain+Intercept\n",
    "\n",
    "matplotlib.pyplot.figure(5)\n",
    "matplotlib.pyplot.plot(C1[:NSampsClass, 0], C1[:NSampsClass, 1], 'bo')\n",
    "matplotlib.pyplot.plot(C2[:NSampsClass, 0], C2[:NSampsClass, 1], 'ro')\n",
    "matplotlib.pyplot.plot(Domain, Disc, 'k-')\n",
    "matplotlib.pyplot.ylim([-1.1,1.3])\n",
    "matplotlib.pyplot.title('Ridge Regression')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this project with the name: OLSandRidgeRegress2DPGader.  Make a New Project for Spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### COMPUTE OUTPUTS ON TRAINING DATA ###\n",
    "yr = AllSampsBias.dot(wr)\n",
    "\n",
    "### PLOT OUTPUTS FROM TRAINING DATA ###\n",
    "matplotlib.pyplot.figure(6)\n",
    "matplotlib.pyplot.plot(range(NSamps), yr, 'm')\n",
    "matplotlib.pyplot.plot(range(NSamps),np.zeros((NSamps,1)), 'b')\n",
    "matplotlib.pyplot.plot(range(NSamps), TargetOutputs, 'k')\n",
    "matplotlib.pyplot.title('TrainingOutputs (Magenta) vs Desired Outputs (Black)')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = y[range(NSampsClass)]\n",
    "y2 = y[range(NSampsClass, NSamps)]\n",
    "Corr1 = np.sum([y1>0])\n",
    "Corr2 = np.sum([y2<0])\n",
    "\n",
    "y1r = yr[range(NSampsClass)]\n",
    "y2r = yr[range(NSampsClass, NSamps)]\n",
    "Corr1r = np.sum([y1r>0])\n",
    "Corr2r = np.sum([y2r<0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Result for Ordinary Least Squares')\n",
    "CorrClassRate=(Corr1+Corr2)/NSamps\n",
    "print(Corr1 + Corr2, 'Correctly Classified for a ', round(100*CorrClassRate), '% Correct Classification \\n')\n",
    "\n",
    "print('Result for Ridge Regression')\n",
    "CorrClassRater=(Corr1r+Corr2r)/NSamps\n",
    "print(Corr1r + Corr2r, 'Correctly Classified for a ', round(100*CorrClassRater), '% Correct Classification \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Make Confusion Matrices ###\n",
    "NumClasses = 2;\n",
    "Cm         = np.zeros((NumClasses,NumClasses))\n",
    "Cm[(0,0)]  = Corr1/NSampsClass\n",
    "Cm[(0,1)]  = (NSampsClass-Corr1)/NSampsClass\n",
    "Cm[(1,0)]  = (NSampsClass-Corr2)/NSampsClass\n",
    "Cm[(1,1)]  = Corr2/NSampsClass\n",
    "Cm           = np.round(100*Cm)\n",
    "print('Confusion Matrix for OLS Regression \\n', Cm, '\\n')\n",
    "\n",
    "Cm           = np.zeros((NumClasses,NumClasses))\n",
    "Cm[(0,0)]    = Corr1r/NSampsClass\n",
    "Cm[(0,1)]    = (NSampsClass-Corr1r)/NSampsClass\n",
    "Cm[(1,0)]    = (NSampsClass-Corr2r)/NSampsClass\n",
    "Cm[(1,1)]    = Corr2r/NSampsClass\n",
    "Cm           = np.round(100*Cm)\n",
    "print('Confusion Matrix for Ridge Regression \\n', Cm, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE:  Run Ordinary Least Squares and Ridge Regression on Spectra and plot the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.4 NEON-RSDI",
   "language": "python",
   "name": "py34"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
