---
syncID: 
title: "Processing NEON eddy-covariance turbulence data with eddy4R-Docker 0.2.0"
description: "This tutorial provides an example of using the eddy4R turbulence ."
dateCreated: 2018-03-06
authors: 
contributors: 
estimatedTime: 
packagesLibraries: 
topics: 
languagesTool: R, Docker
dataProduct: 
code1: 
tutorialSeries: 
urlTitle: 
---

NOTE: .r example file pasted in.  Needs to be converted to .Rmd.


##############################################################################################
#' @title Example workflow for processing NEON eddy-covariance turbulence data with eddy4R-Docker 0.2.0

#' @author
#' David Durden \email{ddurden@battelleecology.org} \cr
#' Stefan Metzger \email{eddy4R.info@gmail.com} \cr
#' Natchaya  Pingintha-Durden \email{ndurden@battelleecology.org}

#' @description 
#' Workflow. Example for processing NEON eddy-covariance turbulence data with \href{https://w3id.org/smetzger/Metzger-et-al_2017_eddy4R-Docker/docker/0.2.0}{eddy4R-Docker}. This example is based on "flow.turb.tow.neon.R" commit d90785a0, and provides a selection of the processing steps that yield the eddy-covariance Level 1 data on the NEON Data Portal (https://w3id.org/smetzger/Metzger-et-al_2017_eddy4R-Docker/portal/0.2.0). It is intended and tested solely for use with the \href{https://w3id.org/smetzger/Metzger-et-al_2017_eddy4R-Docker/docker/0.2.0}{stefanmet/eddy4r:0.2.0} Docker image, and not maintained for compatibility with future eddy4R-Docker versions. After signing up at \href{https://hub.docker.com/}{DockerHub} and installing the \href{https://docs.docker.com/engine/getstarted/step_one/}{Docker host software}, the the image can be downloaded and run as container with the command \code{docker run -d -p 8787:8787 stefanmet/eddy4r:0.2.0}. For additional information please see Sect. 2.6 "Installation and operation" in \href{http://www.geosci-model-dev-discuss.net/gmd-2016-318/}{eddy4R 0.2.0: A DevOps model for community-extensible processing and analysis of eddy-covariance data based on R, Git, Docker and HDF5}.

#' @param Currently none

#' @return Currently none

#' @references
#' License: GNU AFFERO GENERAL PUBLIC LICENSE Version 3, 19 November 2007. \cr
#' Metzger, S., Durden, D., Sturtevant, C., Luo, H., Pingintha-Durden, N., Sachs, T., Serafimovich, A., Hartmann, J., Li, J., Xu, K., and Desai, A. R.: eddy4R: A community-extensible processing, analysis and modeling framework for eddy-covariance data based on R, Git, Docker and HDF5, Geosci. Model Dev. Discuss., 2017, 1-26, doi:10.5194/gmd-2016-318, 2017. \cr
#' NEON Data Portal \url{https://w3id.org/smetzger/Metzger-et-al_2017_eddy4R-Docker/portal/0.2.0}

#' @keywords Central Plains Experimental Range, CPER, eddy4R, eddy-covariance, NEON, turbulence

#' @examples Currently none

#' @seealso Currently none


##############################################################################################
# 1. Initially we set up the environment by installing and loading any packages that may be necessary in the workflow. External packages that are used by eddy4R definition and wrapper functions have already been pre-installed in the Docker image and are excluded here. Additionally we set up our global environment.
##############################################################################################
# load and attach required  packages
  # ensure that workflow dependency packages are installed
  packFlow00 <- c("DataCombine", "ff", "ffbase", "rhdf5","splus2R")
  packFlow01 <- packFlow00[!(packFlow00 %in% installed.packages()[,"Package"])]
  if(base::length(packFlow01) > 0) {
    utils::update.packages(ask = FALSE, checkBuilt = TRUE)
    utils::install.packages(packFlow01)
  }
  base::rm(packFlow00, packFlow01)
  
  # load and attach packages
  library(DataCombine)
  library(eddy4R.base)
  library(eddy4R.qaqc)
  library(ff)           # need to be loaded and attached for arithmetic to work properly on ff objects
  library(ffbase)       # need to be loaded and attached for arithmetic to work properly on ff objects
  # the default for Rscript (and apparently R CMD BATCH) omits package "methods"
  # (https://stat.ethz.ch/R-manual/R-devel/library/utils/html/Rscript.html)
  # this in turn brakes splus2R calls (...could not find function "is"...)
  # hence, exlicitly load and attach package 'methods'
  library(methods)
  library(rhdf5)
  library(splus2R)


##############################################################################################
# 2. Here We set the environmental variables to control this eddy4R example workflow. This allows to modify parameters that control the processing, such as the input file (DIRFILEPARA), input file directory (DIRINP), where a local file system is mounted in the Docker container (DIRMNT), output file directory (DIROUT), the domain the NEON site is located in (DOM), the dates of the files being ingested into the workflow (FILEDP0P), the NEON measurement site (LOC), and whether to set the environmental variables or pass them directly to the eddy4R.base::def.para.flow() function (METHPARAFLOW). Additional information can be found by calling ?eddy4R.base::def.para.flow.
###############################################################################################  
if(TRUE) {
  base::Sys.setenv("DIRFILEPARA" = "/home/eddy/inpExmp/ECTE_dp0p_CPER_2017-05-01.h5")
  base::Sys.setenv("DIRINP" = "/home/eddy/inpExmp")
  # base::Sys.setenv("DIRMNT" = base::paste0("/home/", base::Sys.getenv("USER"), "/eddy"))
  base::Sys.setenv("DIROUT" = "/home/eddy/out")
  base::Sys.setenv("DOM" = "D10")
  base::Sys.setenv("FILEDP0P" = "2017-05-01")
  base::Sys.setenv("LOC" = "CPER")
  base::Sys.setenv("METHPARAFLOW" = "EnvVar")
}
  
  
###############################################################################################
# 3. First we read in all of the metadata. Workflow parameters are read from the environmental variables (see point 2.) or can be specified directly in the eddy4R.base::def.para.flow() function. In this example we use the environmental variables set above. This automatically occurs if the METHPARAFLOW environmental variable is set. After the workflow metadata is read, the science parameters or additional metadata is read in from the input HDF5 file using eddy4R.base::def.neon.read.hdf5.para(). This call is made to read data at all the group levels within the NEON HDF5 structure. For a description of NEON HDF5 structure please see the "readMe" file included in the output HDF5 file, or Metzger et al. (2017).
###############################################################################################
# Initialize your parameter list
Para <- list()

# check environment variables for eddy4R workflow parameter "DirFilePara"
if("METHPARAFLOW" %in% base::names(base::Sys.getenv())) {
  
  Para$Flow <- eddy4R.base::def.para.flow(MethParaFlow = "EnvVar")
  
  # in case no dp0p h5 file is specified for parameters, download gold files and assign corresponding DirFilePara
} else {
  
  #The dates for the run must be specified, this set is for the gold file
  FileDp0p <- "2016-04-24" #Should talk to Stefan about best way to handle this 
  Loc <- "SERC"
  Dom <- "D02"
  Para$Flow <- eddy4R.base::def.para.flow(FileDp0p = FileDp0p, Loc = Loc, Dom = Dom, MethParaFlow = "DfltInp",
                                          urlInpRefe = "https://www.dropbox.com/s/qlp1pyanm5rn2eq/inpRefe_20170308.zip?dl=1",
                                          urlOutRefe = "https://www.dropbox.com/s/60s78ehk7s5j6rd/outRefe_20170612.zip?dl=1")
  
}

# ASSEMBLE PARAMETERS FROM HDF5 FILE

#Determine the horizontal and vertical indices for the tower top measurement level from the input NEON HDF5 file.
  Para$Flow$LevlTowr <- eddy4R.base::def.para.levl.towr(FileIn = Para$Flow$DirFilePara)
  
    # data product level group
  
      # data product group
      for(idx in c("soniAmrs", "irgaCo2", "irgaH2o", "soni")) {

        Para$Flow$dp01[[idx]] <- def.neon.read.hdf5.para(
            DirFileParaLoca = Para$Flow$DirFilePara,
            GrpName = paste0("/", Para$Flow$Loc, "/dp01/data/", idx),
            PosPara = c("PrdIncrAgrDflt", "PrdWndwAgrDflt")
          )
        
      }; rm(idx)
  
  # scientific parameters
  
  # site group
  Para$Sci <- def.neon.read.hdf5.para(
    DirFileParaLoca = Para$Flow$DirFilePara,
    GrpName = "site",
    PosPara = c("Pf$AngEnuXaxs", "Pf$AngEnuYaxs", "Pf$Ofst", "ZoneTime")
  )
  
    # data product level group
    Para$Sci$dp01 <- def.neon.read.hdf5.para(
      DirFileParaLoca = Para$Flow$DirFilePara,
      GrpName = paste0("/", Para$Flow$Loc, "/dp01"),
      PosPara = c("Dspk$Br86$MaxReso", "Dspk$Br86$NumBin", "Dspk$Br86$NumWndw")
    )
    
      # data product group

      
      Para$Sci$dp0p$irga <- def.neon.read.hdf5.para(
        DirFileParaLoca = Para$Flow$DirFilePara,
        GrpName = paste0("/", Para$Flow$Loc, "/dp0p/data/irga_001"),
        PosPara = c("FreqSamp")
      )
      
      Para$Sci$dp0p$irgaMfcSamp <- def.neon.read.hdf5.para(
        DirFileParaLoca = Para$Flow$DirFilePara,
        GrpName = paste0("/", Para$Flow$Loc, "/dp0p/data/irgaMfcSamp_001"),
        PosPara = c("FreqSamp")
      )
      
      Para$Sci$dp0p$irgaSndValiNema <- def.neon.read.hdf5.para(
        DirFileParaLoca = Para$Flow$DirFilePara,
        GrpName = paste0("/", Para$Flow$Loc, "/dp0p/data/irgaSndValiNema_001"),
        PosPara = c("FreqSamp")
      )
      
      Para$Sci$dp0p$soni <- def.neon.read.hdf5.para(
        DirFileParaLoca = Para$Flow$DirFilePara,
        GrpName = paste0("/", Para$Flow$Loc, "/dp0p/data/soni_001"),
        PosPara = c("AngNedZaxs","FreqSamp")
      )
      
      Para$Sci$dp0p$soniAmrs <- def.neon.read.hdf5.para(
        DirFileParaLoca = Para$Flow$DirFilePara,
        GrpName = paste0("/", Para$Flow$Loc, "/dp0p/data/soniAmrs_001"),
        PosPara = c("FreqSamp")
      )
      
    
      # data table
    
        # irgaCo2/RtioMoleDryCo2
        Para$Sci$dp01$irgaCo2$RtioMoleDryCo2 <- def.neon.read.hdf5.para(
          DirFileParaLoca = Para$Flow$DirFilePara,
          GrpName = paste0("/", Para$Flow$Loc, "/dp01/data/irgaCo2/",Para$Flow$LevlTowr,"_30m/rtioMoleDryCo2"),
          PosPara = c("Lag$TimeDiff")
        )
        
        # irgaH2o/RtioMoleDryH2o
        Para$Sci$dp01$irgaH2o$RtioMoleDryH2o <- def.neon.read.hdf5.para(
          DirFileParaLoca = Para$Flow$DirFilePara,
          GrpName = paste0("/", Para$Flow$Loc, "/dp01/data/irgaH2o/",Para$Flow$LevlTowr,"_30m/rtioMoleDryH2o"),
          PosPara = c("Lag$TimeDiff")
        )

  # map parameters (workflow and scientific) to internal process

    # c2r: VersDp output version
    Para$Flow$VersDp <- paste0(Para$Flow$VersDp, "_", format(Sys.time(), "%Y%m%d_%H%M%S_%Z"))


###############################################################################################    
# 4. Set the sampling frequency of the sensors from the input HDF5 metadata for reading in the data and designate plausible ranges for the measurement streams to be tested during the read in of the input HDF5 file. Additionally, we set the working directory and ensure the directories defined above exist (if not, they are created).    
###############################################################################################     
       
    FreqSamp <- list(
      "irga" = Para$Sci$dp0p$irga$FreqSamp,
      "irgaMfcSamp" = Para$Sci$dp0p$irgaMfcSamp$FreqSamp,
      "irgaSndValiNema" = as.numeric(Para$Sci$dp0p$irgaSndValiNema$FreqSamp),
      "soni" = Para$Sci$dp0p$soni$FreqSamp,
      "soniAmrs" = Para$Sci$dp0p$soniAmrs$FreqSamp
    )
    
    #assign list
    Rng <- list()
  
    # irga data
    Rng$irga <- data.frame(
      "densMoleCo2" = c(0,30) * 1e-3,       #[mol m-3]
      "densMoleH2o" = c(0,1500) * 1e-3,     #[mol m-3]
      "presAtm" = c(50,120) * 1e3,          #[Pa]
      "presDiff" = c(-10,1) * 1e3,          #[Pa]
      "rtioMoleDryCo2" = c(300,450) * 1e-6, #[mol mol-1]
      "rtioMoleDryH2o" = c(0,30) * 1e-3,    #[mol mol-1]
      "tempIn" = c(220,330),                #[K]
      "tempOut" = c(220,330)                #[K]
    )
    
    # soni data
    Rng$soni <- data.frame(
      "veloXaxs"=c(-50,50),            #[m s-1]
      "veloYaxs"=c(-50,50),            #[m s-1]
      "veloZaxs"=c(-10,10),            #[m s-1]
      "veloSoni"=c(300,400)            #[m s-1]
    )
    
    # soniAmrs
    Rng$soniAmrs <- data.frame(
      "angXaxs"=c(-360,360),            #[deg]
      "angYaxs"=c(-360,360),            #[deg]
      "angZaxs"=c(-360,360)             #[deg]
    )


# set directories / pathes

  # c2r: working directory
    # default: use temporary working directory on Docker filesystem
    if(is.na(Para$Flow$DirWrk)) {
      
      Para$Flow$DirWrk <- tempdir()
  
    # option: create user-specified working directory, e.g. on host filesystem
    } else {
      
      dir.create(Para$Flow$DirWrk, recursive = TRUE, showWarnings = FALSE)
  
    }
  
    # set working directory
    setwd(Para$Flow$DirWrk)

  # c2r: DirInp, DirMnt input directory
  
    # default: use temporary working directory on Docker filesystem
    if(is.na(Para$Flow$DirInp)) {

      Para$Flow$DirInp <- paste0(Para$Flow$DirWrk, "/inpRefe")
      
    # option: create user-specified input directory (if not existing), e.g. on host filesystem
    } else {
      
      dir.create(Para$Flow$DirInp, recursive = TRUE, showWarnings = FALSE)
      
    }

  # c2r: output directory
    
    # default: use temporary working directory on Docker filesystem
    if(is.na(Para$Flow$DirOut)) {
      
      Para$Flow$DirOut <- paste0(Para$Flow$DirWrk, "/out")
      
    # option: create user-specified input directory (if not existing), e.g. on host filesystem
    } else {
      
      dir.create(Para$Flow$DirOut, recursive = TRUE, showWarnings = FALSE)
      
    }

############################################################################################### 
# 5. After all the workflow parameters and additional metadata have been read in from the file, we can now begin to read the data and quality flag information from the input NEON HDF5 dp0p file. Upon read-in, variable unit information stored as attributes in the HDF5 file are read in and attributed to the data and quality flag information. We then assign all this information using the ff package as binary files to reduce the memory footprint for large datasets.
################################################################################################ 
#READ LIST OF FILES

# assign lists
data <- list()

qfqmFlag <- list()

    

###
# Initializing the date number and output list
numDate <- 0
out <- list()
# start loop around dates
for(date in Para$Flow$FileDp0p) {
numDate <- numDate + 1

  # begin: read raw data
  if(Para$Flow$Read == "hdf5") {
  ###
  
    
  
    ##############################################################################################
    #data inport
    
    # create directory structure
    dir.create(paste(Para$Flow$DirOut, "/", Para$Flow$Loc, "/", Para$Flow$VersDp, sep=""), recursive = TRUE, showWarnings = FALSE)

    # assign list for inputs
    inp <- list()
    
    
    # start loop around instruments
    for(Var in c("irga", "irgaMfcSamp", "irgaSndValiNema", "soni", "soniAmrs")){
    # Var <- c("irga", "irgaMfcSamp", "irgaSndValiNema", "soni", "soniAmrs")[3]

      # call read-in wrapper, assign result as temporary variable
      tmp <- eddy4R.base::wrap.neon.read.hdf5.eddy(
        DirInpLoca = Para$Flow$DirInp,
        SiteLoca = Para$Flow$Loc,
        DateLoca = date,
        VarLoca = Var,
        FreqLoca = FreqSamp[[Var]],
        LevlTowr = Para$Flow$LevlTowr,
        RngLoca = Rng,
        DespLoca = list(widt = Para$Sci$dp01$`Dspk$Br86$NumWndw`,    # c2r: WndwDspkBr86 de-spiking median filter window width [s]
                        nbin = Para$Sci$dp01$`Dspk$Br86$NumBin`,     # c2r: NumDspkBr86Bin de-spiking histogram bins initial number/step size
                        rest = Para$Sci$dp01$`Dspk$Br86$MaxReso`     # c2r: ThshDspkBr86Reso de-spiking resolution threshold
                        )
        )

      #Read in quality flags from HDF5 file
      if(!Var %in% "irgaSndValiNema"){
      
      tmpQfqm <- eddy4R.base::def.neon.read.hdf5.qfqm(
        DirInpLoca = Para$Flow$DirInp,
        SiteLoca = Para$Flow$Loc,
        DateLoca = date,
        VarLoca = Var,
        FreqLoca = FreqSamp[[Var]],
        LevlTowr = Para$Flow$LevlTowr
           )
      
      #Remove time from set of flags
      tmpQfqm <- tmpQfqm[,grep("time",names(tmpQfqm),invert = T)]
      }
      
      # assign result as ffdf to inp
      
        # time domain incl. unit assignment
        if(Var == "irga") {
          
          inp$time <- ff::as.ffdf.data.frame(data.frame(UTC = tmp$time))
          base::attr(x = inp$time$UTC, which = "unit") <- "YYYY-MM-DD hh:mm:ss.sss"

        }

        # sensor data incl. unit assignment
        inp$data[[Var]] <- ff::as.ffdf.data.frame(tmp$data)
        for(idx in base::names(tmp$data)) base::attr(x = inp$data[[Var]][[idx]], which = "unit") <-
          base::attr(x = tmp$data, which = "unit")[[idx]]
        
        if(exists("tmpQfqm")) inp$qfqm[[Var]] <- ff::as.ffdf.data.frame(tmpQfqm)

      # clean up
      rm(tmp)
      if(exists("tmpQfqm")) rm(tmpQfqm)
      invisible(gc())
    
    # end loop around instruments
    }; rm(Var)

    # derived quantities: daily extent, native resolution

      # actual calculation
      inp <- eddy4R.base::wrap.derv.prd.day(
        inpList = inp,
        ZoneTime = Para$Sci$ZoneTime,
        AngZaxsSoniInst = Para$Sci$dp0p$soni$AngNedZaxs
      )

      # print message to screen
      print(paste0(format(Sys.time(), "%F %T"), ": dataset ", date, ": derived quantities calculated (daily extent, native resolution)"))
      
  ###
  # mid: read raw data
  }
  # end: read raw data

  # Assign daily data and attributes to file-backed objects to keep RAM footprint small;
    # case #1: first day (creation)
    if(numDate == 1) {
      
      # data$temp$irga
      data$irga <- inp$data$irga
      qfqmFlag$irga <- inp$qfqm$irga
      
      # data$temp$irgaMfcSamp
      data$irgaMfcSamp <- inp$data$irgaMfcSamp
      qfqmFlag$irgaMfcSamp  <- inp$qfqm$irgaMfcSamp
      
      # data$temp$soni
      data$soni <- inp$data$soni
      qfqmFlag$soni <- inp$qfqm$soni
      # data$temp$soniAmrs
      data$soniAmrs <- inp$data$soniAmrs
      qfqmFlag$soniAmrs <- inp$qfqm$soniAmrs
      # time objects
      data$time <- inp$time
      qfqmFlag$time <- inp$time

    # case #2: subsequent day (appending)
    } else {
      
      # data$temp$irga
      data$irga <- ffbase::ffdfappend(x = data$irga, dat = inp$data$irga)
      qfqmFlag$irga <-  ffbase::ffdfappend(x =qfqmFlag$irga, dat = inp$qfqm$irga)
      
      # data$temp$irgaMfcSamp
      data$irgaMfcSamp <- ffbase::ffdfappend(x = data$irgaMfcSamp, dat = inp$data$irgaMfcSamp)
      qfqmFlag$irgaMfcSamp <-  ffbase::ffdfappend(x =qfqmFlag$irgaMfcSamp, dat = inp$qfqm$irgaMfcSamp)
      
      # data$temp$irgaMfcSamp
      data$irgaSndValiNema <- ffbase::ffdfappend(x = data$irgaSndValiNema, dat = inp$data$irgaSndValiNema)
            qfqmFlag$irgaSndValiNema <-  ffbase::ffdfappend(x =qfqmFlag$irgaSndValiNema, dat = inp$qfqm$irgaSndValiNema)
      
      # data$temp$soni
      data$soni <- ffbase::ffdfappend(x = data$soni, dat = inp$data$soni)
      qfqmFlag$soni <-  ffbase::ffdfappend(x =qfqmFlag$soni, dat = inp$qfqm$soni)
      
      # data$temp$soniAmrs
      data$soniAmrs <- ffbase::ffdfappend(x = data$soniAmrs, dat = inp$data$soniAmrs)
      qfqmFlag$soniAmrs <-  ffbase::ffdfappend(x =qfqmFlag$soniAmrs, dat = inp$qfqm$soniAmrs)
      
      # time objects
      data$time <- ffbase::ffdfappend(x = data$time, dat = inp$time)
      qfqmFlag$time <-  ffbase::ffdfappend(x =qfqmFlag$time, dat = inp$time)
    }

    # clean up
    inp <- NULL
    inpQfqm <- NULL
    invisible(gc())
###
}
# end: loop around dates
###

################################################################################################ 
# 6. Beginning the data analysis (data) and determination of the quality metrics and final quality flag (qfqm). The first step is to grab the half-hourly indices used to extract the data from the file-backed objects into internal memory as a list of data.frames. Then, the lag time correction is applied to the irga data based off the sonic anemometer vertical velocity using the eddy4R.base::def.lag() ) function. After the lag correction has been applied, the half-hourly derived data sub-products "relative humidity" and "dewpoint temperature" are calculated. Then, the data that are provided as NEON Level 1 data products are subsetted from the sensor output and naming syntax are changed to match NEON Level 1 data product output conventions. We use eddy4R.base::wrap.neon.dp01.agr.prd() to calculate the 1-minute averaged data statistics and quality metrics. Finally, we calculate 30-minute data statistics using eddy4R.base::wrap.neon.dp01() and determine the quality metrics and final quality flag using eddy4R.base::wrap.neon.dp01.qfqm.ec().
################################################################################################ 


###
# begin: derived quantities
print(paste0(format(Sys.time(), "%F %T"), ": dataset ", date, " derived quantities (experimental) begin"))
###

# assign list for working parameters and variables
wrk <- list()

#Assign list for outputs from qfqm
qfqm <- list()

# begin and end time for each 30-minute averaging intervals
invisible(lapply(names(data), function(x) {
  if(x == "soniAmrs") {
    wrk$idx[[x]] <<-eddy4R.base::def.idx.agr(time = data$soniAmrs$time, PrdAgr = 1800, FreqLoca = 40)
  }  else {  
    wrk$idx[[x]] <<- eddy4R.base::def.idx.agr(time = data$time$UTC, PrdAgr = 1800, FreqLoca = 20)
  }}))

# determine if the number of iterations to run depending on the Deve flag. If set to TRUE only run a small subset for testing purposes.
if (Para$Flow$Deve == TRUE) {
    iter <- 10
} else {
  iter <- max(sapply(names(wrk$idx), function(x) length(wrk$idx[[x]]$idxBgn)))
}



###
# begin: loop around aggregation interval: 60 s
print(paste0(format(Sys.time(), "%F %T"), ": dataset ", date, " DP01 calculation begin"))
numAgr <- 0
for(idxAgr in 1:iter){
# idxAgr <- 1
numAgr <- numAgr + 1
# create a list identifier for the Aggregation loops
levlAgr <- paste0("numAgr", ifelse(numAgr < 10, paste0("0",numAgr) ,numAgr))
###



  # # explicit solution #2/2: takes about 1 s per averaging interval, or 45 s per day
  # # determine which entries in data correspond to desired aggregation interval    
  # whrData <- which(data$time$UTC >= wrk$timeAgr$BgnIdx[idxAgr] & data$time$UTC < wrk$timeAgr$EndIdx[idxAgr])
  
  # assign list
  wrk$data <- list()
  

    # loop around sensors
    for(idxSens in names(data)){


        
        wrk$data[[idxSens]] <- data[[idxSens]][wrk$idx[[idxSens]]$idxBgn[idxAgr]:wrk$idx[[idxSens]]$idxEnd[idxAgr],]
        wrk$qfqm[[idxSens]] <- qfqmFlag[[idxSens]][wrk$idx[[idxSens]]$idxBgn[idxAgr]:wrk$idx[[idxSens]]$idxEnd[idxAgr],]

      # assign units around variables
      # units are present for POSIXct, but don't show in str()
      for(idxVar in base::names(wrk$data[[idxSens]])) {

        base::attr(x = wrk$data[[idxSens]][[idxVar]], which = "unit") <-
          base::attr(x = data[[idxSens]][[idxVar]], which = "unit")

      }; rm(idxVar)

    }; rm(idxSens)

  # lag-time correction

    # select variables for which to perform
    var <- c("rtioMoleDryCo2", "rtioMoleDryH2o", "rtioMassH2o", "presH2o")

    ###
    # begin: loop around lag correction variables
    tmpRun <- 0
    for(idxVar in var) {
    # idxVar <- var[2]
    tmpRun <- tmpRun + 1
    ###

      # determine lag interactively or use pre-determined lag?
      if((base::length(base::grep(pattern = "CO2", x = idxVar, ignore.case = TRUE)) > 0 && is.na(Para$Sci$dp01$irgaCo2$RtioMoleDryCo2$`Lag$TimeDiff`)) |
         (base::length(base::grep(pattern = "H2O", x = idxVar, ignore.case = TRUE)) > 0 && is.na(Para$Sci$dp01$irgaH2o$RtioMoleDryH2o$`Lag$TimeDiff`))) {

        # actual cross-correlation
        lag <- def.lag(
          refe = wrk$data$soni$veloZaxs,
          meas = wrk$data$irga[[idxVar]],
          # dataRefe = wrk$data$soni,
          # max. 2 s lag time
          # atm. transport time = 1 s = separation distance 0.15 m / minimum mean horizontal wind speed 0.15 m s-1
          # tube transport time = 0.15 s = volume of tube and cell 0.03 L / flow rate 12 L min-1 * 60 s min-1
          lagMax = 2 * FreqSamp$irga,
          lagCnst = TRUE,
          # only negative lags permitted (reference leads)
          lagNgtvPstv = c("n", "p", "np")[1],
          # consider positive and negative extrema
          lagAll = TRUE,
          freq = FreqSamp$irga,
          hpf = TRUE
        )

      } else {

        # assign pre-determined lag-times from Para list
        lag <- list()
        lag$lag <- ifelse(base::length(base::grep(pattern = "CO2", x = idxVar, ignore.case = TRUE)) > 0,
                             Para$Sci$dp01$irgaCo2$RtioMoleDryCo2$`Lag$TimeDiff`,
                             Para$Sci$dp01$irgaH2o$RtioMoleDryH2o$`Lag$TimeDiff`)
        lag$corrCros <- NaN

      }

      # shift and reassign data
      # perform here, so all subsequent analyses (EC, spectra) can use the corrected data for any important variable
      # this means that flow rates, air densities are not shifted individually for CO2 and H2O
      # that should be alright, as no high-frequency calculations are performed anymore at this stage
      # only statistics (averages...) is calculated over marginally different samples
      tmpAttr <- attributes(wrk$data$irga[[idxVar]])$unit
      if(!is.na(lag$lag)) wrk$data$irga[[idxVar]] <- DataCombine:::shift(VarVect = wrk$data$irga[[idxVar]], shiftBy = - lag$lag, reminder = FALSE)
      attributes(wrk$data$irga[[idxVar]])$unit <- tmpAttr; rm(tmpAttr)
      
      # store lag times
      if(tmpRun == 1) {
        tmpLag <- lag$lag / FreqSamp$irga
        tmpCorrCros <- lag$corrCros
      } else {
        tmpLag <- c(tmpLag, lag$lag / FreqSamp$irga)
        tmpCorrCros <- c(tmpCorrCros, lag$corrCros)
      }

    ###
    # end: loop around lag correction variables
    }
    ###
    
    # clean up
    names(tmpLag) <- var
      tmpLag <- data.frame(t(tmpLag))
    names(tmpCorrCros) <- var
      tmpCorrCros <- data.frame(t(tmpCorrCros))
    rm(tmpRun, lag, idxVar, var)

  # derived quantities (after synchronization)
    # fast air temperature
    wrk$data$soni$T_air_SONIC <- unlist(wrk$data$soni$tempSoni / (1 + 0.51 * wrk$data$irga$rtioMassH2o))
    base::attr(x = wrk$data$soni$T_air_SONIC, which = "unit") <- "K"

    # water vapor saturation pressure (ambient)
    if(!is.na(mean(wrk$data$soni$T_air_SONIC, na.rm=TRUE))) {
      
      wrk$data$irga$presH2oSatAtm <- unlist(def.pres.h2o.sat.temp.mag(temp=wrk$data$soni$T_air_SONIC))
      
    } else {
      
      wrk$data$irga$presH2oSatAtm <- rep(NaN, length(wrk$data$soni$T_air_SONIC))
      
    }
    base::attr(x = wrk$data$irga$presH2oSatAtm, which = "unit") <- "Pa"

    # RH (ambient) incl. adjustment of partial pressure from cell to ambient (Dalton's law)
    wrk$data$irga$rhAtm <- def.rh.pres.h2o.pres.sat.h2o(presH2o = wrk$data$irga$presH2o, presH2oSat = wrk$data$irga$presH2oSatAtm) *
      mean(wrk$data$irga$presAtm, na.rm=TRUE) / mean(wrk$data$irga$presSum, na.rm=TRUE)

    # dew point (ambient)
    wrk$data$irga$tempDew <- def.temp.dew.pres.h2o.temp.mag(presH2o = wrk$data$irga$presH2o, temp = wrk$data$soni$T_air_SONIC)

  # assemble data for Level 1 data product generation
  # can also happen after dp01 calculation
    
    # assign lists
      # for data
      wrk$tmp$data <- list()
    
      # for qfqm
      wrk$tmp$qfqm <- list()
    
    # assemble data
      # for soni
      wrk$tmp$data$soni <- data.frame(stringsAsFactors = FALSE,
                                      "veloXaxsErth" = wrk$data$soni$veloXaxs,
                                      "veloYaxsErth" = wrk$data$soni$veloYaxs, 
                                      "veloZaxsErth" = wrk$data$soni$veloZaxs,
                                      "veloXaxsYaxsErth" = wrk$data$soni$veloXaxsYaxsErth,
                                      "angZaxsErth" = wrk$data$soni$angZaxsErth,                                                      # still needs to be generated
                                      "tempSoni" = wrk$data$soni$tempSoni,
                                      "tempAir" = wrk$data$soni$T_air_SONIC
                                      )
      
      # for soniAmrs
      wrk$tmp$data$soniAmrs <- data.frame(stringsAsFactors = FALSE,
                                          "angNedXaxs" = wrk$data$soniAmrs$angXaxs,
                                          "angNedYaxs" = wrk$data$soniAmrs$angYaxs,
                                          "angNedZaxs" = wrk$data$soniAmrs$angZaxs)
     
      # for irgaCo2
      wrk$tmp$data$irgaCo2 <- data.frame(stringsAsFactors = FALSE,
                                         "rtioMoleDryCo2" = wrk$data$irga$rtioMoleDryCo2,
                                         "densMoleCo2" = wrk$data$irga$densMoleCo2, 
                                         "presAtm" = wrk$data$irga$presAtm,
                                         "presSum" = wrk$data$irga$presSum,
                                         "frt00Samp" = wrk$data$irgaMfcSamp$frt00,
                                         "tempAve" = wrk$data$irga$tempMean
                                         )
    
      # for irgaH2o
      wrk$tmp$data$irgaH2o <- data.frame(stringsAsFactors = FALSE,
                                         "rtioMoleDryH2o" = wrk$data$irga$rtioMoleDryH2o,
                                         "densMoleH2o" = wrk$data$irga$densMoleH2o, 
                                         "tempDew" = wrk$data$irga$tempDew,
                                         "presAtm" = wrk$data$irga$presAtm,
                                         "presSum" = wrk$data$irga$presSum,
                                         "frt00Samp" = wrk$data$irgaMfcSamp$frt00,
                                         "tempAve" = wrk$data$irga$tempMean
                                         )

  # calculate data products 
      #Calculate 1 and 2 minute data products
    wrk$dp01AgrSub[[levlAgr]] <- eddy4R.base::wrap.neon.dp01.agr.prd(inpList = wrk)
  
    # 30-minute data products
    # call dp01 processing, assign each result as list element numAgr in wrk$dp01
     wrk$dp01[[levlAgr]] <- eddy4R.base::wrap.neon.dp01(
      # assign data: data.frame or list of type numeric or integer
      data = wrk$tmp$data,
      # if data is a list, which list entries should be processed into Level 1 data products?
      # defaults to NULL which expects data to be a data.frame
      idx = c("soni", "soniAmrs", "irgaCo2", "irgaH2o")
    )
  
    # message to screen
    print(paste0(format(Sys.time(), "%F %T"), ": Beginning the qfqm data processing for data in loop...", idxAgr))
  
    # Calculate the quality metrics and determine the final quality flag
    wrk$qfqmOut[[levlAgr]] <- eddy4R.base::wrap.neon.dp01.qfqm.ec(qfqm = wrk$qfqm,
                                                                  idx = c("soni", "soniAmrs", "irgaCo2", "irgaH2o"),
                                                                  MethMeas = "ecte",
                                                                  RptExpd = TRUE )

  # clean up
  wrk$data <- NULL
  wrk$tmp <- NULL
  invisible(gc())
###
# end loop around aggregation interval
}
print(paste0(format(Sys.time(), "%F %T"), ": dataset ", date, " DP01 calculation complete"))
###

################################################################################################ 
# 7. Now, we aggregate the results of the data analysis and determination of the quality metrics and final quality flag. The first step is to aggregate the half-hourly sets of data and qfqm from the processing. Then, we plot the final quality flag and it's relation to the alpha (fraction of quality flags set high from a set of sensor and statistical plausibility tests flags) and beta (fraction of quality flags not available due to missing data) quality metrics.
################################################################################################ 
# concatenate results
out <- eddy4R.base::def.agr.ecte.dp01(inpList = wrk, MethSubAgr = TRUE, MethUcrt = FALSE)

#generate  qfqm example table for 
# qfqmExmp <- eddy4R.base::def.agr.ecte.dp01(inpList = wrk, MethSubAgr = TRUE, MethUcrt = FALSE, RptExpd = TRUE)


        inpPlot <- data.frame(time = format(as.POSIXct(out$time$irgaCo2$timeBgn, format="%Y-%m-%d %H:%M:%S"), format="%H:%M"),
                                qfFinl = out$qfqm$soni$qfFinl$veloXaxsYaxsErth,
                              qmAlph = out$qfqm$soni$qmAlph$veloXaxsYaxsErth,
                              qmBeta = out$qfqm$soni$qmBeta$veloXaxsYaxsErth)
        
          library(ggplot2)
          # p <- ggplot(inpPlot, aes(x=time, y=qfFinl))+
          #   geom_bar(alpha=0.75, stat = "identity") +
          #   geom_line(aes(y=qmAlph), colour = "red")
          plot = ggplot(inpPlot, aes(time)) + 
            geom_bar(aes(y = qfFinl, fill= "qfFinl"), stat="identity") +
            geom_line(aes(y = qmAlph, group = 1, color = "qmAlph"), size = 1, linetype = "dashed") +
            geom_line(aes(y = qmBeta, group = 2, color = "qmBeta"), size = 1, linetype = "dashed") +
            ggtitle("veloXaxsYaxsErth") +
            scale_colour_manual(" ", values=c("qfFinl" = "black", "qmAlph" = "blue", "qmBeta" = "red")) +
            scale_fill_manual("",values="black") +
            theme(legend.key = element_blank(),
                  legend.title = element_blank(),
                  legend.box = "vertical",
                  plot.title = element_text(size=14, face="bold.italic", hjust = 0.5),
                  axis.title.x = element_text(size=14, face="bold"),
                  axis.title.y = element_text(size=14, face="bold")) +
            ylim(-0.2,1.2) +
            labs(y = "qfqm")

          print(plot)
          
  # clean up
  wrk$dp01 <- NULL
  wrk$dp01AgrSub <- NULL
  wrk$qfqmOut <- NULL

################################################################################################ 
# 8. Lastly, we prepare the data for output and write it to the dp01 output HDF5 file. We first create the skeleton structure of the NEON HDF5 file using eddy4R.base::def.hdf5.crte(). We then perform some packaging of the results to match the NEON HDF5 structure and write the output to the NEON dp01 HDF5 file.
################################################################################################ 
  
#Git rid of the qm column after the example
lapply(names(out$qfqm), function(x){
  out$qfqm[[x]]$qm <<- NULL
})  

# Call the NEON HDF5 structure generating for expanded file
eddy4R.base::def.hdf5.crte(Date = date, Site = Para$Flow$Loc, LevlTowr = Para$Flow$LevlTowr, 
                           DirOut = base::paste0(Para$Flow$DirOut, "/", Para$Flow$Loc, "/", Para$Flow$VersDp),
                           Dom = Para$Flow$Dom, MethExpd = TRUE,
                           fileNameReadMe = "/home/eddy/inpExmp/ECTE_HDF5_readme.txt",
                           fileNameObjDesc = "/home/eddy/inpExmp/ECTE_HDF5_object_description.csv")

# Determine the output filename of the file that was just created  
FileOut <- base::list.files(path = base::paste0(Para$Flow$DirOut, "/", Para$Flow$Loc, "/", Para$Flow$VersDp), pattern = ".h5", full.names = TRUE)
 
# Call the wrapper function to package and write data to output HDF5 files, both basic and expanded
eddy4R.base::wrap.hdf5.wrte.dp01(inpList = out, FileIn = base::paste0(Para$Flow$DirInp,"/","ECTE_dp0p_",  Para$Flow$Loc, "_", date, ".h5"), FileOut = FileOut, SiteLoca = Para$Flow$Loc, LevlTowr = Para$Flow$LevlTowr, MethUcrt = FALSE, MethSubAgr = TRUE)

################################################################################################
# End of workflow template
